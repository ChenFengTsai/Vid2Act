{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Task Stratified Extraction\n",
      "Configuration: Each task gets 10 episodes\n",
      "\n",
      "button-press-topdown:\n",
      "  Total episodes: 1740\n",
      "  Extracting 1 episode from each of 10 tiers\n",
      "  ✓ Copied 10 episodes\n",
      "\n",
      "door-open:\n",
      "  Total episodes: 1740\n",
      "  Extracting 1 episode from each of 10 tiers\n",
      "  ✓ Copied 10 episodes\n",
      "\n",
      "drawer-close:\n",
      "  Total episodes: 1740\n",
      "  Extracting 1 episode from each of 10 tiers\n",
      "  ✓ Copied 10 episodes\n",
      "\n",
      "peg-insert-side:\n",
      "  Total episodes: 1740\n",
      "  Extracting 1 episode from each of 10 tiers\n",
      "  ✓ Copied 10 episodes\n",
      "\n",
      "pick-place:\n",
      "  Total episodes: 1740\n",
      "  Extracting 1 episode from each of 10 tiers\n",
      "  ✓ Copied 10 episodes\n",
      "\n",
      "push:\n",
      "  Total episodes: 1740\n",
      "  Extracting 1 episode from each of 10 tiers\n",
      "  ✓ Copied 10 episodes\n",
      "\n",
      "TOTAL: 60 episodes across all tasks\n",
      "Output: /storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/stratified_per_task_10\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Simplified: Extract 10 stratified episodes PER TASK (independent).\n",
    "Each task independently stratifies into 10 tiers and selects 1 episode per tier.\n",
    "Total: 60 episodes (10 per task × 6 tasks)\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "SOURCE_TASK_DIRS = [\n",
    "    \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/dreamer_button-press-topdown\",\n",
    "    \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/dreamer_door-open\",\n",
    "    \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/dreamer_drawer-close\",\n",
    "    \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/dreamer_peg-insert-side\",\n",
    "    \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/dreamer_pick-place\",\n",
    "    \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/dreamer_push\"\n",
    "]\n",
    "\n",
    "OUTPUT_FOLDER = \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/stratified_per_task_10\"\n",
    "\n",
    "N_TIERS_PER_TASK = 10  # Each task split into 10 performance tiers\n",
    "EPISODES_PER_TIER = 1  # 1 episode per tier → 10 total per task\n",
    "\n",
    "def main():\n",
    "    print(f\"Per-Task Stratified Extraction\")\n",
    "    print(f\"Configuration: Each task gets {N_TIERS_PER_TASK} episodes\\n\")\n",
    "    \n",
    "    output_path = Path(OUTPUT_FOLDER)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    total_copied = 0\n",
    "    \n",
    "    for task_dir in SOURCE_TASK_DIRS:\n",
    "        task_name = Path(task_dir).name\n",
    "        task_short = \"_\".join(task_name.split(\"_\")[1:])  # Remove 'dreamer_' prefix\n",
    "        \n",
    "        metrics_file = Path(task_dir) / \"metrics.jsonl\"\n",
    "        train_eps_folder = Path(task_dir) / \"train_eps\"\n",
    "        \n",
    "        if not metrics_file.exists() or not train_eps_folder.exists():\n",
    "            print(f\"⚠ {task_short}: Missing files, skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Load episodes for this task\n",
    "        episodes = []\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                if 'train_episodes' in data and 'train_return' in data:\n",
    "                    ep_idx = int(data['train_episodes']) - 1\n",
    "                    train_return = data['train_return']\n",
    "                    episodes.append((ep_idx, train_return))\n",
    "        \n",
    "        # Sort by score (descending)\n",
    "        sorted_episodes = sorted(episodes, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Stratify this task independently\n",
    "        tier_size = len(sorted_episodes) // N_TIERS_PER_TASK\n",
    "        selected_episodes = []\n",
    "        \n",
    "        print(f\"{task_short}:\")\n",
    "        print(f\"  Total episodes: {len(episodes)}\")\n",
    "        print(f\"  Extracting 1 episode from each of {N_TIERS_PER_TASK} tiers\")\n",
    "        \n",
    "        for tier_idx in range(N_TIERS_PER_TASK):\n",
    "            tier_start = tier_idx * tier_size\n",
    "            tier_end = (tier_idx + 1) * tier_size if tier_idx < N_TIERS_PER_TASK - 1 else len(sorted_episodes)\n",
    "            \n",
    "            tier_episodes = sorted_episodes[tier_start:tier_end]\n",
    "            \n",
    "            if len(tier_episodes) > 0:\n",
    "                # Pick middle episode from this tier\n",
    "                mid_idx = len(tier_episodes) // 2\n",
    "                ep_idx = tier_episodes[mid_idx][0]\n",
    "                selected_episodes.append(ep_idx)\n",
    "        \n",
    "        # Copy selected episodes\n",
    "        task_output_folder = output_path / task_short\n",
    "        task_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        all_npz_files = sorted(train_eps_folder.glob('*.npz'))\n",
    "        copied = 0\n",
    "        \n",
    "        for ep_idx in sorted(selected_episodes):\n",
    "            if ep_idx < len(all_npz_files):\n",
    "                src = all_npz_files[ep_idx]\n",
    "                dst = task_output_folder / src.name\n",
    "                shutil.copy2(src, dst)\n",
    "                copied += 1\n",
    "        \n",
    "        total_copied += copied\n",
    "        print(f\"  ✓ Copied {copied} episodes\\n\")\n",
    "    \n",
    "    print(f\"TOTAL: {total_copied} episodes across all tasks\")\n",
    "    print(f\"Output: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Task Stratified Extraction (Top 50%)\n",
      "Configuration: Each task gets 10 episodes from its top 50% of returns\n",
      "\n",
      "button-press-topdown:\n",
      "  Total episodes: 1740\n",
      "  Top 50% episodes: 870\n",
      "  Extracting 1 episode from each of 10 tiers (within top 50%)\n",
      "  ✓ Copied 10 episodes\n",
      "\n",
      "door-open:\n",
      "  Total episodes: 1740\n",
      "  Top 50% episodes: 870\n",
      "  Extracting 1 episode from each of 10 tiers (within top 50%)\n",
      "  ✓ Copied 10 episodes\n",
      "\n",
      "drawer-close:\n",
      "  Total episodes: 1740\n",
      "  Top 50% episodes: 870\n",
      "  Extracting 1 episode from each of 10 tiers (within top 50%)\n",
      "  ✓ Copied 10 episodes\n",
      "\n",
      "peg-insert-side:\n",
      "  Total episodes: 1740\n",
      "  Top 50% episodes: 870\n",
      "  Extracting 1 episode from each of 10 tiers (within top 50%)\n",
      "  ✓ Copied 10 episodes\n",
      "\n",
      "pick-place:\n",
      "  Total episodes: 1740\n",
      "  Top 50% episodes: 870\n",
      "  Extracting 1 episode from each of 10 tiers (within top 50%)\n",
      "  ✓ Copied 10 episodes\n",
      "\n",
      "push:\n",
      "  Total episodes: 1740\n",
      "  Top 50% episodes: 870\n",
      "  Extracting 1 episode from each of 10 tiers (within top 50%)\n",
      "  ✓ Copied 10 episodes\n",
      "\n",
      "TOTAL: 60 episodes across all tasks\n",
      "Output: /storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/stratified_per_task_10_top50\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Modified: Extract 10 stratified episodes PER TASK (independent),\n",
    "but only from the TOP 50% of episodes for that task.\n",
    "\n",
    "Each task:\n",
    "1. Sort episodes by train_return (descending).\n",
    "2. Keep only the top 50% highest-return episodes.\n",
    "3. Stratify that subset into 10 tiers and select 1 episode per tier.\n",
    "\n",
    "Total: 60 episodes (10 per task × 6 tasks), all from the top half.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "SOURCE_TASK_DIRS = [\n",
    "    \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/dreamer_button-press-topdown\",\n",
    "    \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/dreamer_door-open\",\n",
    "    \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/dreamer_drawer-close\",\n",
    "    \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/dreamer_peg-insert-side\",\n",
    "    \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/dreamer_pick-place\",\n",
    "    \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/dreamer_push\"\n",
    "]\n",
    "\n",
    "OUTPUT_FOLDER = \"/storage/ssd1/richtsai1103/vid2act/pretrain/metaworld/pretrain_data/stratified_per_task_10_top50\"\n",
    "\n",
    "N_TIERS_PER_TASK = 10  # Each task split into 10 performance tiers (within top 50%)\n",
    "EPISODES_PER_TIER = 1  # 1 episode per tier → 10 total per task\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(f\"Per-Task Stratified Extraction (Top 50%)\")\n",
    "    print(f\"Configuration: Each task gets {N_TIERS_PER_TASK} episodes from its top 50% of returns\\n\")\n",
    "    \n",
    "    output_path = Path(OUTPUT_FOLDER)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    total_copied = 0\n",
    "    \n",
    "    for task_dir in SOURCE_TASK_DIRS:\n",
    "        task_name = Path(task_dir).name\n",
    "        task_short = \"_\".join(task_name.split(\"_\")[1:])  # Remove 'dreamer_' prefix\n",
    "        \n",
    "        metrics_file = Path(task_dir) / \"metrics.jsonl\"\n",
    "        train_eps_folder = Path(task_dir) / \"train_eps\"\n",
    "        \n",
    "        if not metrics_file.exists() or not train_eps_folder.exists():\n",
    "            print(f\"⚠ {task_short}: Missing files, skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Load episodes for this task\n",
    "        episodes = []\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                if 'train_episodes' in data and 'train_return' in data:\n",
    "                    ep_idx = int(data['train_episodes']) - 1\n",
    "                    train_return = data['train_return']\n",
    "                    episodes.append((ep_idx, train_return))\n",
    "        \n",
    "        if len(episodes) == 0:\n",
    "            print(f\"⚠ {task_short}: No episodes found, skipping\")\n",
    "            continue\n",
    "\n",
    "        # Sort by score (descending)\n",
    "        sorted_episodes = sorted(episodes, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # --- NEW: keep only top 50% of episodes ---\n",
    "        half_len = int(np.ceil(len(sorted_episodes) * 0.5))\n",
    "        top_episodes = sorted_episodes[:half_len]\n",
    "        # -------------------------------------------\n",
    "        \n",
    "        # Stratify this task independently (only using the top 50%)\n",
    "        tier_size = max(1, len(top_episodes) // N_TIERS_PER_TASK)\n",
    "        selected_episodes = []\n",
    "        \n",
    "        print(f\"{task_short}:\")\n",
    "        print(f\"  Total episodes: {len(episodes)}\")\n",
    "        print(f\"  Top 50% episodes: {len(top_episodes)}\")\n",
    "        print(f\"  Extracting {EPISODES_PER_TIER} episode from each of {N_TIERS_PER_TASK} tiers (within top 50%)\")\n",
    "        \n",
    "        for tier_idx in range(N_TIERS_PER_TASK):\n",
    "            tier_start = tier_idx * tier_size\n",
    "            # Make sure the last tier goes to the end\n",
    "            if tier_idx < N_TIERS_PER_TASK - 1:\n",
    "                tier_end = (tier_idx + 1) * tier_size\n",
    "            else:\n",
    "                tier_end = len(top_episodes)\n",
    "            \n",
    "            tier_episodes = top_episodes[tier_start:tier_end]\n",
    "            \n",
    "            if len(tier_episodes) > 0:\n",
    "                # Pick middle episode from this tier\n",
    "                mid_idx = len(tier_episodes) // 2\n",
    "                ep_idx = tier_episodes[mid_idx][0]\n",
    "                selected_episodes.append(ep_idx)\n",
    "        \n",
    "        # Deduplicate in case of any overlap due to small dataset\n",
    "        selected_episodes = sorted(list(set(selected_episodes)))[:N_TIERS_PER_TASK]\n",
    "        \n",
    "        # Copy selected episodes\n",
    "        task_output_folder = output_path / task_short\n",
    "        task_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        all_npz_files = sorted(train_eps_folder.glob('*.npz'))\n",
    "        copied = 0\n",
    "        \n",
    "        for ep_idx in sorted(selected_episodes):\n",
    "            if ep_idx < len(all_npz_files):\n",
    "                src = all_npz_files[ep_idx]\n",
    "                dst = task_output_folder / src.name\n",
    "                shutil.copy2(src, dst)\n",
    "                copied += 1\n",
    "        \n",
    "        total_copied += copied\n",
    "        print(f\"  ✓ Copied {copied} episodes\\n\")\n",
    "    \n",
    "    print(f\"TOTAL: {total_copied} episodes across all tasks\")\n",
    "    print(f\"Output: {output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from math import isfinite\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def load_metrics_from_jsonl(jsonl_path):\n",
    "    metrics = []\n",
    "    with open(jsonl_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                metric = json.loads(line)\n",
    "                metrics.append(metric)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Warning: Could not parse line: {line[:100]}... Error: {e}\")\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def is_valid_scalar(value):\n",
    "    if value is None or isinstance(value, (bool, str)):\n",
    "        return False\n",
    "    try:\n",
    "        v = float(value)\n",
    "        return isfinite(v)\n",
    "    except (TypeError, ValueError):\n",
    "        return False\n",
    "\n",
    "\n",
    "def write_to_tensorboard(metrics, logdir=\"./runs/metrics\"):\n",
    "    Path(logdir).mkdir(parents=True, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir=logdir)\n",
    "\n",
    "    total_scalars = 0\n",
    "\n",
    "    for metric_dict in metrics:\n",
    "        if \"step\" not in metric_dict:\n",
    "            continue\n",
    "\n",
    "        step = int(metric_dict[\"step\"])\n",
    "\n",
    "        for key, value in metric_dict.items():\n",
    "            if key == \"step\":\n",
    "                continue\n",
    "            if not is_valid_scalar(value):\n",
    "                continue\n",
    "\n",
    "            value = float(value)\n",
    "            # group under 'scalars/' tag as you wanted\n",
    "            writer.add_scalar(f\"scalars/{key}\", value, global_step=step)\n",
    "            total_scalars += 1\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    print(f\"Wrote {total_scalars} scalar points to TensorBoard at {logdir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 3828 scalar points to TensorBoard at ./runs/metrics\n"
     ]
    }
   ],
   "source": [
    "metrics_file = \"/storage/ssd1/richtsai1103/vid2act/log/metaworld/mt6/drawer_open/original_seed0/metrics.jsonl\"\n",
    "metrics = load_metrics_from_jsonl(metrics_file)\n",
    "write_to_tensorboard(metrics, logdir=\"./runs/metrics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('hrssm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f7283e4099e674ce1a2c6afb904b708499aaa8b744778061c58955dd37a9ab7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
